{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":86672,"databundleVersionId":9823921,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom scipy import stats\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Input\nfrom sklearn.preprocessing import StandardScaler, RobustScaler\nfrom sklearn.impute import KNNImputer\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import r2_score","metadata":{"execution":{"iopub.status.busy":"2024-10-25T17:38:03.554674Z","iopub.execute_input":"2024-10-25T17:38:03.555191Z","iopub.status.idle":"2024-10-25T17:38:15.251427Z","shell.execute_reply.started":"2024-10-25T17:38:03.555120Z","shell.execute_reply":"2024-10-25T17:38:15.249736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the training data\nx_train_df = pd.read_csv('/kaggle/input/task-1-brain-age-prediction/X_train.csv')\ny_train_df = pd.read_csv('/kaggle/input/task-1-brain-age-prediction/y_train.csv')\nx_test_df = pd.read_csv('/kaggle/input/task-1-brain-age-prediction/X_test.csv')\n\nx_train = x_train_df.drop(columns=['id'])\nx_test = x_test_df.drop(columns=['id'])\ny_train = y_train_df['y']","metadata":{"execution":{"iopub.status.busy":"2024-10-25T17:38:15.254036Z","iopub.execute_input":"2024-10-25T17:38:15.254821Z","iopub.status.idle":"2024-10-25T17:38:15.958578Z","shell.execute_reply.started":"2024-10-25T17:38:15.254751Z","shell.execute_reply":"2024-10-25T17:38:15.957089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop columns with constant value\nconstant_columns = x_train.apply(lambda col: col.nunique(dropna=True) == 1)\nx_train = x_train.loc[:, ~constant_columns]\nx_test = x_test.loc[:, ~constant_columns]\n\n# Outlier detection\n# Z-scores\nmean = np.nanmean(x_train, axis=0)\nstd_dev = np.nanstd(x_train, axis=0)\nz_scores = np.abs((x_train - mean) / std_dev)\nthreshold = 3.5\noutliers = (z_scores > threshold).any(axis=1)\nx_train_filtered = x_train[~outliers]\ny_train_filtered = y_train[~outliers]\n\nprint(\"Number of rows removed: \", outliers.value_counts().get(True))","metadata":{"execution":{"iopub.status.busy":"2024-10-25T17:38:15.960126Z","iopub.execute_input":"2024-10-25T17:38:15.960602Z","iopub.status.idle":"2024-10-25T17:38:16.157912Z","shell.execute_reply.started":"2024-10-25T17:38:15.960546Z","shell.execute_reply":"2024-10-25T17:38:16.156422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Imputation of missing values\nimputer = KNNImputer()\nx_train_imputed = imputer.fit_transform(x_train_filtered)\nx_test_imputed = imputer.fit_transform(x_test)\n\n# Scale the data\nscaler = StandardScaler()\nx_train_scaled = scaler.fit_transform(x_train_imputed)\nx_train_scaled = pd.DataFrame(x_train_scaled)\nx_test_scaled = scaler.fit_transform(x_test_imputed)\nx_test_scaled = pd.DataFrame(x_test_scaled)","metadata":{"execution":{"iopub.status.busy":"2024-10-25T17:38:16.159498Z","iopub.execute_input":"2024-10-25T17:38:16.159945Z","iopub.status.idle":"2024-10-25T17:38:22.040261Z","shell.execute_reply.started":"2024-10-25T17:38:16.159901Z","shell.execute_reply":"2024-10-25T17:38:22.038895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Feature selection\n# # Compute correlation matrix\n# correlation_matrix = x_train_scaled.corrwith(y_train_filtered)\n# # Select features with high correlation (e.g., absolute correlation > 0.1)\n# selected_features = correlation_matrix[abs(correlation_matrix) > 0.1].index\n# # Keep only the selected features in x_train\n# x_train_selected = x_train_scaled[selected_features]\n# x_test_selected = x_test_scaled[selected_features]\n\n# print(\"Number of features selected: \", selected_features.size)\n\nfrom sklearn.feature_selection import SelectKBest, mutual_info_regression\n\n#Select top 100 features with highest mutual information\nselection = SelectKBest(mutual_info_regression, k=100).fit(x_train_scaled, y_train_filtered)\nx_train_selected = selection.transform(x_train_scaled)\nx_test_selected = selection.transform(x_test_scaled)","metadata":{"execution":{"iopub.status.busy":"2024-10-25T17:38:22.043052Z","iopub.execute_input":"2024-10-25T17:38:22.043854Z","iopub.status.idle":"2024-10-25T17:38:27.515822Z","shell.execute_reply.started":"2024-10-25T17:38:22.043801Z","shell.execute_reply":"2024-10-25T17:38:27.514408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build the model\nmodel = Sequential()\nmodel.add(Input(shape=(x_train_selected.shape[-1], )))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(1))\n\nprint(x_train_selected.shape, y_train_filtered.shape)\n\n# Compile and train the model\nmodel.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\nhistory = model.fit(x_train_selected, y_train_filtered, epochs=30, batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2024-10-25T17:38:27.517550Z","iopub.execute_input":"2024-10-25T17:38:27.518000Z","iopub.status.idle":"2024-10-25T17:38:32.244532Z","shell.execute_reply.started":"2024-10-25T17:38:27.517957Z","shell.execute_reply":"2024-10-25T17:38:32.242798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model on the training data itself\ny_train_pred = model.predict(x_train_selected)\nr2_train = r2_score(y_train_filtered, y_train_pred)\n# Print R^2 score for the training set\nprint(f\"Training R² Score: {r2_train}\")\n\n# Use the trained model to predict the ages\nage_predictions = model.predict(x_test_selected)\n# Convert predictions to a pandas DataFrame\npredictions_df = pd.DataFrame({\n    'id': range(len(age_predictions)),  # Assign IDs starting from 0\n    'y': age_predictions.flatten()  # Flatten if predictions are in a 2D array\n})\n# Save the DataFrame to a CSV file\npredictions_df.to_csv('predictions_MLP.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-10-25T17:38:32.246445Z","iopub.execute_input":"2024-10-25T17:38:32.246867Z","iopub.status.idle":"2024-10-25T17:38:32.614630Z","shell.execute_reply.started":"2024-10-25T17:38:32.246819Z","shell.execute_reply":"2024-10-25T17:38:32.613067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import make_pipeline\n\npoly_reg_model = make_pipeline(PolynomialFeatures(degree=1), LinearRegression())\npoly_reg_model.fit(x_train_selected, y_train_filtered)\ny_train_pred = poly_reg_model.predict(x_train_selected)\n\nr2_train = r2_score(y_train_filtered, y_train_pred)\nprint(f\"Training R² Score: {r2_train}\")\n\n# Use the trained model to predict the ages\nage_predictions = poly_reg_model.predict(x_test_selected)\n# Convert predictions to a pandas DataFrame\npredictions_df = pd.DataFrame({\n    'id': range(len(age_predictions)),  # Assign IDs starting from 0\n    'y': age_predictions.flatten()  # Flatten if predictions are in a 2D array\n})\n# Save the DataFrame to a CSV file\npredictions_df.to_csv('predictions_LR.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-10-25T17:38:58.440503Z","iopub.execute_input":"2024-10-25T17:38:58.440972Z","iopub.status.idle":"2024-10-25T17:38:58.494939Z","shell.execute_reply.started":"2024-10-25T17:38:58.440930Z","shell.execute_reply":"2024-10-25T17:38:58.492952Z"},"trusted":true},"execution_count":null,"outputs":[]}]}